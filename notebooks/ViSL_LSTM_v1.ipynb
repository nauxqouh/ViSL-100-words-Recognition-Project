{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399b108c",
   "metadata": {},
   "source": [
    "## 0. Preparing Input for Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae927558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 14:04:56.109489: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/xuannguyet/Documents/SUDOCODE25/ViSL-100-words-Recognition-Project\")\n",
    "\n",
    "from src.utils.utils import update_label_map\n",
    "from config.paths import label_map_path, augmented_data_dir\n",
    "import json\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# update_label_map(augmented_data_dir, label_map_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99908f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 samples across 100 classes.\n",
      "Train samples: 16000\n",
      "Val samples: 2000\n",
      "Test samples: 2000\n"
     ]
    }
   ],
   "source": [
    "VAL_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "DATA_PATH = augmented_data_dir\n",
    "\n",
    "with open(label_map_path, 'r', encoding='utf-8') as f:\n",
    "    label_map = json.load(f)\n",
    "    \n",
    "labels = label_map.keys()\n",
    "\n",
    "all_files = []\n",
    "for label in labels:\n",
    "    label_dir = os.path.join(DATA_PATH, label)\n",
    "    for path in glob.glob(os.path.join(label_dir, '*.npy')):\n",
    "        all_files.append((path, label_map[label]))\n",
    "\n",
    "print(f\"Found {len(all_files)} samples across {len(label_map)} classes.\")\n",
    "\n",
    "paths, labels = zip(*all_files)\n",
    "train_files, temp_files, y_train, y_temp = train_test_split(\n",
    "    paths, labels,\n",
    "    test_size=VAL_SPLIT + TEST_SPLIT,\n",
    "    shuffle=True, stratify=labels, random_state=42\n",
    ")\n",
    "val_files, test_files, y_val, y_test = train_test_split(\n",
    "    temp_files, y_temp,\n",
    "    test_size=TEST_SPLIT / (VAL_SPLIT + TEST_SPLIT),\n",
    "    shuffle=True, stratify=y_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_files)}\")\n",
    "print(f\"Val samples: {len(val_files)}\")\n",
    "print(f\"Test samples: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad7309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def _load_npy(path, label):\n",
    "    data = np.load(path.decode('utf-8'), allow_pickle=True)\n",
    "    frames = []\n",
    "    for frame in data:\n",
    "        # frame = [left_hand, right_hand, pose]\n",
    "        concat = np.concatenate(frame)  # (n_keypoints_total, 3)\n",
    "        frames.append(concat.flatten())  # vector 1D\n",
    "    seq = np.stack(frames)  # (20, 177)\n",
    "    return seq.astype(np.float32), np.int32(label)\n",
    "\n",
    "def parse_fn(path, label):\n",
    "    seq, lbl = tf.numpy_function(_load_npy, [path, label], [tf.float32, tf.int32])\n",
    "    seq.set_shape([20, 177])  # ví dụ shape cố định (frames, features)\n",
    "    lbl.set_shape([])\n",
    "    return seq, lbl\n",
    "\n",
    "def make_dataset(paths, labels, shuffle=False, repeat=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((list(paths), list(labels)))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(len(paths), reshuffle_each_iteration=True)\n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    ds = ds.map(parse_fn, num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = make_dataset(train_files, y_train, shuffle=True, repeat=True)\n",
    "val_ds   = make_dataset(val_files, y_val)\n",
    "test_ds  = make_dataset(test_files, y_test)\n",
    "\n",
    "steps_per_epoch = len(train_files) // BATCH_SIZE\n",
    "validation_steps = len(val_files) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e816c096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(None, 20, 177), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(tf.data.experimental.get_structure(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f8d669b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence batch shape: (32, 20, 177)\n",
      "Label batch shape: (32,)\n",
      "First sequence sample:\n",
      " tf.Tensor(\n",
      "[[0.57240224 0.809707   0.         ... 0.4343589  0.83919317 0.        ]\n",
      " [0.5732106  0.8029092  0.         ... 0.42893115 0.8417214  0.        ]\n",
      " [0.5609208  0.76240504 0.         ... 0.43171892 0.8365464  0.        ]\n",
      " ...\n",
      " [0.52867615 0.66626966 0.         ... 0.43032545 0.86773926 0.        ]\n",
      " [0.54509044 0.7284521  0.         ... 0.42815924 0.8564395  0.        ]\n",
      " [0.56173635 0.7838249  0.         ... 0.43270388 0.8522289  0.        ]], shape=(20, 177), dtype=float32)\n",
      "First label: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-29 14:05:57.901670: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for seq_batch, lbl_batch in train_ds.take(1):\n",
    "    print(\"Sequence batch shape:\", seq_batch.shape)\n",
    "    print(\"Label batch shape:\", lbl_batch.shape)\n",
    "    print(\"First sequence sample:\\n\", seq_batch[0])\n",
    "    print(\"First label:\", lbl_batch[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de319f",
   "metadata": {},
   "source": [
    "## 1. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "471fb129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">177</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">888,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,700</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m177\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │       \u001b[38;5;34m888,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,574,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,574,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m25,700\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,467,556</span> (17.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,467,556\u001b[0m (17.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,462,948</span> (17.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,462,948\u001b[0m (17.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,608</span> (18.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,608\u001b[0m (18.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional,GlobalAveragePooling1D, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "inputs = tf.keras.Input(shape=(20, 177))\n",
    "\n",
    "# First LSTM\n",
    "x = Bidirectional(LSTM(256, return_sequences=True, dropout=0.3))(inputs)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Second LSTM\n",
    "x = Bidirectional(LSTM(256, return_sequences=True, dropout=0.3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Third LSTM\n",
    "x = Bidirectional(LSTM(256, dropout=0.3))(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Dense layers\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "# Output layer\n",
    "num_classes = len(np.unique(y_train))\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb53b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac042509",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'Models/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(checkpoint_dir, 'ViSL_model_v1.keras')\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_path,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a14b1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772ms/step - accuracy: 0.0355 - loss: 4.5640\n",
      "Epoch 1: val_loss improved from None to 2.23057, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 817ms/step - accuracy: 0.0815 - loss: 3.9480 - val_accuracy: 0.3513 - val_loss: 2.2306\n",
      "Epoch 2/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672ms/step - accuracy: 0.3184 - loss: 2.3600\n",
      "Epoch 2: val_loss improved from 2.23057 to 1.04225, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m359s\u001b[0m 717ms/step - accuracy: 0.4075 - loss: 2.0243 - val_accuracy: 0.6895 - val_loss: 1.0423\n",
      "Epoch 3/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726ms/step - accuracy: 0.6204 - loss: 1.2457\n",
      "Epoch 3: val_loss improved from 1.04225 to 0.53853, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 779ms/step - accuracy: 0.6573 - loss: 1.0959 - val_accuracy: 0.7989 - val_loss: 0.5385\n",
      "Epoch 4/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671ms/step - accuracy: 0.7345 - loss: 0.7872\n",
      "Epoch 4: val_loss improved from 0.53853 to 0.41229, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m354s\u001b[0m 708ms/step - accuracy: 0.7437 - loss: 0.7401 - val_accuracy: 0.8438 - val_loss: 0.4123\n",
      "Epoch 5/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 589ms/step - accuracy: 0.7910 - loss: 0.5766\n",
      "Epoch 5: val_loss improved from 0.41229 to 0.33374, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 632ms/step - accuracy: 0.8066 - loss: 0.5395 - val_accuracy: 0.8508 - val_loss: 0.3337\n",
      "Epoch 6/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630ms/step - accuracy: 0.8465 - loss: 0.4252\n",
      "Epoch 6: val_loss improved from 0.33374 to 0.18791, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1588s\u001b[0m 3s/step - accuracy: 0.8606 - loss: 0.3857 - val_accuracy: 0.9380 - val_loss: 0.1879\n",
      "Epoch 7/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - accuracy: 0.8978 - loss: 0.2924 \n",
      "Epoch 7: val_loss improved from 0.18791 to 0.15871, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5369s\u001b[0m 11s/step - accuracy: 0.9051 - loss: 0.2771 - val_accuracy: 0.9385 - val_loss: 0.1587\n",
      "Epoch 8/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501ms/step - accuracy: 0.9232 - loss: 0.2209\n",
      "Epoch 8: val_loss improved from 0.15871 to 0.05771, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 534ms/step - accuracy: 0.9325 - loss: 0.1959 - val_accuracy: 0.9773 - val_loss: 0.0577\n",
      "Epoch 9/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step - accuracy: 0.9502 - loss: 0.1458\n",
      "Epoch 9: val_loss improved from 0.05771 to 0.01786, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 520ms/step - accuracy: 0.9524 - loss: 0.1412 - val_accuracy: 0.9909 - val_loss: 0.0179\n",
      "Epoch 10/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.9566 - loss: 0.1276\n",
      "Epoch 10: val_loss did not improve from 0.01786\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 565ms/step - accuracy: 0.9599 - loss: 0.1197 - val_accuracy: 0.9814 - val_loss: 0.0571\n",
      "Epoch 11/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421ms/step - accuracy: 0.9625 - loss: 0.1119\n",
      "Epoch 11: val_loss did not improve from 0.01786\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 450ms/step - accuracy: 0.9667 - loss: 0.0987 - val_accuracy: 0.9879 - val_loss: 0.0307\n",
      "Epoch 12/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.9731 - loss: 0.0822\n",
      "Epoch 12: val_loss did not improve from 0.01786\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 517ms/step - accuracy: 0.9708 - loss: 0.0879 - val_accuracy: 0.9819 - val_loss: 0.0271\n",
      "Epoch 13/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.9754 - loss: 0.0812\n",
      "Epoch 13: val_loss did not improve from 0.01786\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 524ms/step - accuracy: 0.9746 - loss: 0.0821 - val_accuracy: 0.9894 - val_loss: 0.0426\n",
      "Epoch 14/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 534ms/step - accuracy: 0.9816 - loss: 0.0676\n",
      "Epoch 14: val_loss improved from 0.01786 to 0.00282, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 568ms/step - accuracy: 0.9806 - loss: 0.0674 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 15/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step - accuracy: 0.9813 - loss: 0.0606\n",
      "Epoch 15: val_loss did not improve from 0.00282\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 514ms/step - accuracy: 0.9776 - loss: 0.0699 - val_accuracy: 0.9950 - val_loss: 0.0114\n",
      "Epoch 16/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 0.9800 - loss: 0.0673\n",
      "Epoch 16: val_loss did not improve from 0.00282\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 513ms/step - accuracy: 0.9805 - loss: 0.0644 - val_accuracy: 0.9985 - val_loss: 0.0035\n",
      "Epoch 17/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508ms/step - accuracy: 0.9870 - loss: 0.0446\n",
      "Epoch 17: val_loss improved from 0.00282 to 0.00077, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 543ms/step - accuracy: 0.9849 - loss: 0.0478 - val_accuracy: 1.0000 - val_loss: 7.6869e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step - accuracy: 0.9843 - loss: 0.0545\n",
      "Epoch 18: val_loss improved from 0.00077 to 0.00023, saving model to Models/checkpoints/ViSL_model_v1.keras\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 512ms/step - accuracy: 0.9839 - loss: 0.0568 - val_accuracy: 1.0000 - val_loss: 2.2998e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step - accuracy: 0.9927 - loss: 0.0270\n",
      "Epoch 19: val_loss did not improve from 0.00023\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 506ms/step - accuracy: 0.9914 - loss: 0.0301 - val_accuracy: 0.9985 - val_loss: 0.0049\n",
      "Epoch 20/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step - accuracy: 0.9882 - loss: 0.0413\n",
      "Epoch 20: val_loss did not improve from 0.00023\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 515ms/step - accuracy: 0.9901 - loss: 0.0359 - val_accuracy: 0.9980 - val_loss: 0.0045\n",
      "Epoch 21/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - accuracy: 0.9833 - loss: 0.0603\n",
      "Epoch 21: val_loss did not improve from 0.00023\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 516ms/step - accuracy: 0.9827 - loss: 0.0588 - val_accuracy: 0.9985 - val_loss: 0.0032\n",
      "Epoch 22/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step - accuracy: 0.9903 - loss: 0.0333\n",
      "Epoch 22: val_loss did not improve from 0.00023\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 516ms/step - accuracy: 0.9898 - loss: 0.0357 - val_accuracy: 0.9940 - val_loss: 0.0144\n",
      "Epoch 23/100\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 525ms/step - accuracy: 0.9843 - loss: 0.0569\n",
      "Epoch 23: val_loss did not improve from 0.00023\n",
      "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 554ms/step - accuracy: 0.9861 - loss: 0.0494 - val_accuracy: 0.9914 - val_loss: 0.0179\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1441bfd90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a7bda9",
   "metadata": {},
   "source": [
    "## 2. Evaluate on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d8b46bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 1.3878e-04\n",
      "Test Accuracy: 1.0000\n",
      "Test Loss: 0.0001\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('Models/checkpoints/ViSL_model_v1.keras')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_ds)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
